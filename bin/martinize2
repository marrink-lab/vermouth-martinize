#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright 2018 University of Groningen
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
High level API for Martinize2
"""

import argparse
import functools
import logging
import itertools
import textwrap
from pathlib import Path
import sys

import vermouth
import vermouth.forcefield
from vermouth import DATA_PATH
from vermouth.dssp import dssp
from vermouth.dssp.dssp import (
    AnnotateDSSP,
    AnnotateMartiniSecondaryStructures,
    AnnotateResidues,
)
from vermouth.log_helpers import (StyleAdapter, BipolarFormatter,
                                  CountingHandler, TypeAdapter)
from vermouth import selectors
from vermouth.map_input import (
    read_mapping_directory,
    generate_all_self_mappings,
    combine_mappings
)

# TODO Since vermouth's __init__.py does some logging (KDTree), this may or may
# not work as intended. Investigation required.

LOGGER = TypeAdapter(logging.getLogger('vermouth'))

PRETTY_FORMATTER = logging.Formatter(fmt='{levelname:>8} - {type} - {message}',
                                     style='{')
DETAILED_FORMATTER = logging.Formatter(fmt='{levelname:>8} - {type} - {name} - {message}',
                                       style='{')

COUNTER = CountingHandler()

# Control above what level message we want to count
COUNTER.setLevel(logging.WARNING)

CONSOLE_HANDLER = logging.StreamHandler()
FORMATTER = BipolarFormatter(DETAILED_FORMATTER,
                             PRETTY_FORMATTER,
                             logging.DEBUG,
                             logger=LOGGER)
CONSOLE_HANDLER.setFormatter(FORMATTER)
LOGGER.addHandler(CONSOLE_HANDLER)
LOGGER.addHandler(COUNTER)

LOGGER = StyleAdapter(LOGGER)

VERSION = 'martinize with vermouth {}'.format(vermouth.__version__)


def read_system(path, ignore_resnames=()):
    """
    Read a system from a PDB or GRO file.

    This function guesses the file type based on the file extension.

    The resulting system does not have a force field and may not have edges.
    """
    system = vermouth.System()
    file_extension = path.suffix.upper()[1:]  # We do not keep the dot
    if file_extension in ['PDB', 'ENT']:
        vermouth.PDBInput(str(path), exclude=ignore_resnames).run_system(system)
    elif file_extension in ['GRO']:
        vermouth.GROInput(str(path), exclude=ignore_resnames).run_system(system)
    else:
        raise ValueError('Unknown file extension "{}".'.format(file_extension))
    return system


def pdb_to_universal(system, delete_unknown=False, force_field=None,
                     write_graph=None, write_repair=None, write_canon=None):
    """
    Convert a system read from the PDB to a clean canonical atomistic system.
    """
    if force_field is None:
        force_field = vermouth.forcefield.get_native_force_field('universal')
    canonicalized = system.copy()
    canonicalized.force_field = force_field
    LOGGER.info('Guessing the bonds.', type='step')
    vermouth.MakeBonds().run_system(canonicalized)
    vermouth.MergeNucleicStrands().run_system(canonicalized)
    if write_graph is not None:
        vermouth.pdb.write_pdb(canonicalized, str(write_graph), omit_charges=True)
    LOGGER.info('Repairing the graph.', type='step')
    vermouth.RepairGraph(delete_unknown=delete_unknown, include_graph=False).run_system(canonicalized)
    if write_repair is not None:
        vermouth.pdb.write_pdb(canonicalized, str(write_repair),
                               omit_charges=True, nan_missing_pos=True)
    LOGGER.info('Dealing with modifications.', type='step')
    vermouth.CanonicalizeModifications().run_system(canonicalized)
    if write_canon is not None:
        vermouth.pdb.write_pdb(canonicalized, str(write_canon),
                               omit_charges=True, nan_missing_pos=True)
    vermouth.AttachMass(attribute='mass').run_system(canonicalized)
    return canonicalized


def martinize(system, mappings, to_ff, delete_unknown=False):
    """
    Convert a system from one force field to an other at lower resolution.
    """
    LOGGER.info('Creating the graph at the target resolution.', type='step')
    vermouth.DoMapping(mappings=mappings,
                       to_ff=to_ff,
                       delete_unknown=delete_unknown,
                       attribute_keep=('cgsecstruct', )).run_system(system)
    LOGGER.info('Averaging the coordinates.', type='step')
    vermouth.DoAverageBead(ignore_missing_graphs=True).run_system(system)
    LOGGER.info('Applying the blocks.', type='step')
    vermouth.ApplyBlocks().run_system(system)
    LOGGER.info('Applying the links.', type='step')
    vermouth.DoLinks().run_system(system)
    LOGGER.info('Placing the charge dummies.', type='step')
    vermouth.LocateChargeDummies().run_system(system)
    return system


def write_gmx_topology(system, top_path, deduplicate=True, header=()):
    """
    Writes a Gromacs .top file for the specified system.
    """
    if not system.molecules:
        raise ValueError('No molecule in the system. Nothing to write.')
    if deduplicate:
        # Deduplicate the moleculetypes in order to write each molecule ITP only
        # once.
        molecule_types = [[system.molecules[0], [system.molecules[0]]], ]
        for molecule in system.molecules[1:]:
            for molecule_type, share_moltype in molecule_types:
                if molecule.share_moltype_with(molecule_type):
                    share_moltype.append(molecule)
                    break
            else:  # no break
                molecule_types.append([molecule, [molecule, ]])
    else:
        molecule_types = [[molecule, [molecule, ]] for molecule in system.molecules]
    # Write the ITP files for the moleculetypes.
    for molidx, (molecule_type, _) in enumerate(molecule_types):
        molecule_type.moltype = 'molecule_{}'.format(molidx)
        with open('molecule_{}.itp'.format(molidx), 'w') as outfile:
            vermouth.gmx.itp.write_molecule_itp(molecule_type, outfile, header=header)
    # Reorganize the molecule type assignment to write the top file.
    # The top file "molecules" section lists the molecules in the same order
    # as in the structure and group them. To do the grouping, we associate each
    # molecule to the molecule type (its name actually) instead of associating
    # the molecule types with the molecules as we did above.
    molecule_to_type = {}
    for molecule_type, share_moltype in molecule_types:
        for molecule in share_moltype:
            molecule_to_type[molecule] = molecule_type.moltype
    # Write the top file
    max_name_length = max(len(molecule_type.moltype)
                          for molecule_type, _ in molecule_types)
    template = textwrap.dedent("""\
        #include "martini.itp"
        {includes}

        [ system ]
        Title of the system

        [ molecules ]
        {molecules}
    """)
    include_string = '\n'.join(
        '#include "{}.itp"'.format(molecule_type.moltype)
        for molecule_type, _ in molecule_types
    )
    molecule_groups = itertools.groupby(system.molecules,
                                        key=lambda x: molecule_to_type[x])
    molecule_string = '\n'.join(
        '{mtype:<{length}}    {num}'
        .format(mtype=mtype, num=len(list(group)), length=max_name_length)
        for mtype, group in molecule_groups
    )
    with open(str(top_path), 'w') as outfile:
        outfile.write(
            textwrap.dedent(
                template.format(
                    includes=include_string,
                    molecules=molecule_string
                )
            )
        )


def _cys_argument(value):
    """
    Convert and validate the value of the cys option for argparse.

    Parameters
    ----------
    value: str
        The value given to the command line.

    Return
    ------
    str or float
        A value understood by the main function. This value can be either
        'auto' to detect cystein bridges automatically based on a default
        distance, 'none' to not have cystein bridges, or a float value to set
        cystein bridges based on a distance threshold.

    Raises
    ------
    argparse.ArgumentError
        Raised when the value cannot be converted.
    """
    try:
        result = float(value)
    except ValueError:
        lowered = value.lower()
        if lowered in ('auto', 'none'):
            return lowered
        raise argparse.ArgumentError(
            argument='-cys',
            message=('The value of the "cys" option must be "auto", "none", '
                     'or a distance in nanometers.'),
        )
    else:
        return result


def entry():
    """
    Parses commandline arguments and performs the logic.
    """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument('-V', '--version', action='version', version=VERSION)

    file_group = parser.add_argument_group('Input and output files')
    file_group.add_argument('-f', dest='inpath', required=True, type=Path,
                            help='Input file (PDB|GRO)')
    file_group.add_argument('-x', dest='outpath', required=True, type=Path,
                            help='Output coarse grained structure (PDB)')
    file_group.add_argument('-o', dest='top_path', type=Path,
                            help='Output topology (TOP)')
    file_group.add_argument('-sep', dest='keep_duplicate_itp',
                            action='store_true', default=False,
                            help='Write separate topologies for identical chains')
    file_group.add_argument('-merge', dest='merge_chains',
                            type=lambda x: x.split(','), action='append',
                            help='Merge chains: e.g. -merge A,B,C (+)')
    file_group.add_argument('-ignore', dest='ignore_res', action='append',
                            default=[],
                            help='Ignore residues with that name.')

    ff_group = parser.add_argument_group('Force field selection')
    ff_group.add_argument('-ff', dest='to_ff', default='martini22',
                          help='Which forcefield to use')
    ff_group.add_argument('-from', dest='from_ff', default='universal',
                          help='Force field of the original structure.')
    ff_group.add_argument('-ff-dir', dest='extra_ff_dir', action='append',
                          type=Path, default=[],
                          help='Additional repository for custom force fields.')
    ff_group.add_argument('-map-dir', dest='extra_map_dir', action='append',
                          type=Path, default=[],
                          help='Additional repository for mapping files.')

    posres_group = parser.add_argument_group('Position restraints')
    posres_group.add_argument('-p', dest='posres', type=str.lower,
                              choices=('none', 'all', 'backbone'), default='none',
                              help='Output position restraints (none/all/backbone)')
    posres_group.add_argument('-pf', dest='posres_fc', type=float, default=1000,
                              help='Position restraints force constant in kJ/mol/nm^2')
    secstruct_group = parser.add_argument_group('Secondary structure handling')
    secstruct_exclusion = secstruct_group.add_mutually_exclusive_group()
    secstruct_exclusion.add_argument('-dssp', nargs='?', const='dssp',
                                     help='DSSP executable for determining structure')
    secstruct_exclusion.add_argument('-ss', dest='ss', type=str.upper,
                                     metavar='SEQUENCE',
                                     help=('Manually set the secondary '
                                           'structure of the proteins.'))
    secstruct_exclusion.add_argument('-collagen', action='store_true', default=False,
                                     help='Use collagen parameters')
    secstruct_group.add_argument('-ed', dest='extdih', action='store_true', default=False,
                                 help=('Use dihedrals for extended regions '
                                       'rather than elastic bonds'))

    rb_group = parser.add_argument_group('Protein elastic network')
    rb_group.add_argument('-elastic', action='store_true', default=False,
                          help='Write elastic bonds')
    rb_group.add_argument('-ef', dest='rb_force_constant', type=float, default=500,
                          help='Elastic bond force constant Fc in kJ/mol/nm^2')
    rb_group.add_argument('-el', dest='rb_lower_bound', type=float, default=0.5,
                          help='Elastic bond lower cutoff: F = Fc if rij < lo')
    rb_group.add_argument('-eu', dest='rb_upper_bound', type=float, default=0.9,
                          help='Elastic bond upper cutoff: F = 0  if rij > up')
    rb_group.add_argument('-ea', dest='rb_decay_factor', type=float, default=0,
                          help='Elastic bond decay factor a')
    rb_group.add_argument('-ep', dest='rb_decay_power', type=float, default=0,
                          help='Elastic bond decay power p')
    rb_group.add_argument('-em', dest='rb_minimum_force', type=float, default=0,
                          help='Remove elastic bonds with force constant lower than this')
    rb_group.add_argument('-eb', dest='rb_selection',
                          type=lambda x: x.split(','), default=None,
                          help='Comma separated list of bead names for elastic bonds')

    prot_group = parser.add_argument_group('Protein description')
    prot_group.add_argument('-nt', dest='neutral_termini',
                            action='store_true', default=False,
                            help='Set neutral termini (charged is default)')
    prot_group.add_argument('-scfix', dest='scfix',
                            action='store_true', default=False,
                            help='Apply side chain corrections.')
    prot_group.add_argument('-cys', dest='cystein_bridge',
                            type=_cys_argument,
                            default='none', help='Cystein bonds')

    debug_group = parser.add_argument_group('Debugging options')
    debug_group.add_argument('-write-graph', type=Path, default=None,
                             help='Write the graph as PDB after the MakeBonds step.')
    debug_group.add_argument('-write-repair', type=Path, default=None,
                             help=('Write the graph as PDB after the '
                                   'RepairGraph step. The resulting file may '
                                   'contain "nan" coordinates making it '
                                   'unreadable by most softwares.'))
    debug_group.add_argument('-write-canon', type=Path, default=None,
                             help=('Write the graph as PDB after the '
                                   'CanonicalizeModifications step. The '
                                   'resulting file may contain "nan" '
                                   'coordinates making it unreadable by most '
                                   'softwares.'))
    debug_group.add_argument('-v', dest='verbosity', action='count',
                             help='Enable debug logging output. Can be given '
                                  'multiple times.', default=0)

    args = parser.parse_args()

    loglevels = {0: logging.INFO, 1: logging.DEBUG, 2: 5}
    LOGGER.setLevel(loglevels[args.verbosity])

    known_force_fields = vermouth.forcefield.find_force_fields(
        Path(DATA_PATH) / 'force_fields'
    )
    known_mappings = read_mapping_directory(Path(DATA_PATH) / 'mappings')

    # Add user force fields and mappings
    for directory in args.extra_ff_dir:
        try:
            vermouth.forcefield.find_force_fields(directory, known_force_fields)
        except FileNotFoundError:
            msg = '"{}" given to the -ff-dir option should be a directory.'
            raise ValueError(msg.format(directory))
    for directory in args.extra_map_dir:
        try:
            partial_mapping = read_mapping_directory(directory)
        except NotADirectoryError:
            msg = '"{}" given to the -map-dir option should be a directory.'
            raise ValueError(msg.format(directory))
        combine_mappings(known_mappings, partial_mapping)

    # Build self mappings
    partial_mapping = generate_all_self_mappings(known_force_fields.values())
    combine_mappings(known_mappings, partial_mapping)

    from_ff = args.from_ff
    if args.to_ff not in known_force_fields:
        raise ValueError('Unknown force field "{}".'.format(args.to_ff))
    if args.from_ff not in known_force_fields:
        raise ValueError('Unknown force field "{}".'.format(args.from_ff))
    if from_ff not in known_mappings or args.to_ff not in known_mappings[from_ff]:
        raise ValueError('No mapping known to go from "{}" to "{}".'
                         .format(from_ff, args.to_ff))

    # Reading the input structure.
    # So far, we assume we only go from atomistic to martini. We want the
    # input structure to be a clean universal system.
    # For now at least, we silently delete molecules with unknown blocks.
    system = read_system(args.inpath, ignore_resnames=args.ignore_res)
    system = pdb_to_universal(
        system,
        delete_unknown=True,
        force_field=known_force_fields[from_ff],
        write_graph=args.write_graph,
        write_repair=args.write_repair,
        write_canon=args.write_canon,
    )

    target_ff = known_force_fields[args.to_ff]
    if args.dssp is not None:
        AnnotateDSSP(executable=args.dssp, savedir='.').run_system(system)
        AnnotateMartiniSecondaryStructures().run_system(system)
    elif args.ss is not None:
        AnnotateResidues(attribute='secstruct', sequence=args.ss,
                         molecule_selector=selectors.is_protein).run_system(system)
        AnnotateMartiniSecondaryStructures().run_system(system)
    elif args.collagen:
        if not target_ff.has_feature('collagen'):
            LOGGER.warning('The force field "{}" does not have specific '
                           'parameters for collagen (-collagen).',
                           target_ff.name, type='missing-feature')
        AnnotateResidues(attribute='cgsecstruct', sequence='F',
                         molecule_selector=selectors.is_protein).run_system(system)
    if args.extdih and not target_ff.has_feature('extdih'):
        LOGGER.warning('The force field "{}" does not define dihedral '
                       'angles for extended regions of proteins (-extdih).',
                       target_ff.name, type='missing-feature')
    vermouth.SetMoleculeMeta(extdih=args.extdih).run_system(system)
    if args.neutral_termini and not target_ff.has_feature('neutral_termini'):
        LOGGER.warning('The force field "{}" does not have specific '
                       'parameters for neutral termini (-nt).',
                       target_ff.name, type='missing-feature')
    vermouth.SetMoleculeMeta(neutral_termini=args.neutral_termini).run_system(system)
    if args.scfix and not target_ff.has_feature('scfix'):
        LOGGER.warning('The force field "{}" does not define angle and '
                       'torsion for the side chain corrections (-scfix).',
                       target_ff.name, type='missing-feature')
    vermouth.SetMoleculeMeta(scfix=args.scfix).run_system(system)

    ss_sequence = list(itertools.chain(*(
        dssp.sequence_from_residues(molecule, 'secstruct')
        for molecule in system.molecules
        if selectors.is_protein(molecule)
    )))

    if args.cystein_bridge == 'none':
        vermouth.RemoveCysteinBridgeEdges().run_system(system)
    elif args.cystein_bridge != 'auto':
        vermouth.AddCysteinBridgesThreshold(args.cystein_bridge).run_system(system)

    # Run martinize on the system.
    system = martinize(
        system,
        mappings=known_mappings,
        to_ff=known_force_fields[args.to_ff],
        delete_unknown=True,
    )

    # Apply a rubber band elastic network is required.
    if args.elastic:
        LOGGER.info('Setting the rubber bands.', type='step')
        if args.rb_selection is not None:
            selector = functools.partial(
                selectors.proto_select_attribute_in,
                attribute='atomname',
                values=args.rb_selection,
            )
        else:
            selector = selectors.select_backbone
        rubber_band_processor = vermouth.ApplyRubberBand(
            lower_bound=args.rb_lower_bound,
            upper_bound=args.rb_upper_bound,
            decay_factor=args.rb_decay_factor,
            decay_power=args.rb_decay_power,
            base_constant=args.rb_force_constant,
            minimum_force=args.rb_minimum_force,
            selector=selector,
        )
        rubber_band_processor.run_system(system)

    # Apply position restraints if required.
    if args.posres != 'none':
        LOGGER.info('Applying position restraints.', type='step')
        node_selectors = {'all': selectors.select_all,
                          'backbone': selectors.select_backbone}
        node_selector = node_selectors[args.posres]
        vermouth.ApplyPosres(node_selector, args.posres_fc).run_system(system)

    # Merge chains if required.
    if args.merge_chains:
        for chain_set in args.merge_chains:
            vermouth.MergeChains(chain_set).run_system(system)

    LOGGER.info('Writing output.', type='step')
    # Write the topology if requested
    header = [
        'This file was generated using the following command:',
        ' '.join(sys.argv),
        VERSION,
    ]
    if None not in ss_sequence:
        header += [
            'The following sequence of secondary structure ',
            'was used for the full system:',
            ''.join(ss_sequence),
        ]

    if args.top_path is not None:
        write_gmx_topology(system, args.top_path,
                           deduplicate=not args.keep_duplicate_itp,
                           header=header)

    # Write a PDB file.
    vermouth.pdb.write_pdb(system, str(args.outpath), omit_charges=True)


if __name__ == '__main__':
    entry()
